#!/bin/bash
#SBATCH --job-name=MONC_ScFull_128
#SBATCH --output=%x.o%j
  # %x gives job-name (SLURM_JOB_NAME)
  # %j gives jobid (individual SLURM_JOB_ID)
  # %A gives jobid (master     SLURM_ARRAY_JOB_ID)
  # %a gives array task id number
  #  https://slurm.schedmd.com/sbatch.html
#SBATCH --open-mode=append
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=128
#SBATCH --ntasks=128
#SBATCH --cpus-per-task=1
#SBATCH --time=00:20:00
#SBATCH --account=n02
#SBATCH --partition=standard
#SBATCH --qos=standard

### Push to development queue
## #SBATCH --reservation=shortqos
## #SBATCH --qos=short

# MODULES
module restore PrgEnv-cray
module load cpe-gnu
module load gcc/9.3.0
module load cray-netcdf-hdf5parallel
module load cray-hdf5-parallel
module load cray-fftw/3.3.8.7
module load petsc/3.13.3
module load atp
export ATP_ENABLED=1

module list
pwd

ulimit -c unlimited

# set variables for submission command----------------------
export SUBMISSION_SCRIPT_NAME=asubmonc.sb
export MONC_EXEC=./build/bin/monc_driver.exe

export TESTCASE=testcases/ScFull_128.mcf
export STDOUT_DIR=monc_stdout
export CP_DIR=checkpoint_files
export RUN_NAME=${SLURM_JOB_NAME}_dump_
export NPES=${SLURM_NTASKS}
export MAX_CONTINUATION_RUNS=200
# ----------------------------------------------------------

echo -e "\nSubmission time: $(date)\n"

. misc/continuation.sbatch.sh

run_monc

# output job statisitcs to .o (%x.o%j)
echo -e "\nCompletion time: $(date)\n"
scontrol show job $SLURM_JOB_ID
sstat $SLURM_JOB_ID --format="AveRSS,MaxRSS"
#  Run after batch job concludes: seff $SLURM_JOB_ID
